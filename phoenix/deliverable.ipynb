{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884427c3",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Hypothesis Generation\n",
    "\n",
    "This notebook is adapted from `quickstart_local.ipynb` and contains the following modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291b1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5' # Set to the index of the GPU you want to use; see visible GPUs with `nvidia-smi` on command line\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from hypothesaes.quickstart import train_sae, interpret_sae, generate_hypotheses, evaluate_hypotheses\n",
    "from hypothesaes.embedding import get_local_embeddings\n",
    "from hypothesaes.llm_local import get_vllm_engine\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "assert current_dir.endswith(\"phoenix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073234cd",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset I will be using is [Twitter Tweet Sentiments (27.5k)](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset), a collection of 27,480 tweets and the associated sentiments. 5496 of these tweets are used for validation during SAE training and 5496 tweets used for holdout evaluation. The target variable is the `sentiment` column, which can be `negative`, `neutral`, or `positive`, and we are interested in seeing what features of the `text` column predict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6fccc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19413</th>\n",
       "      <td>ba7bbe76fe</td>\n",
       "      <td>: saw it yesterday. Pretty good.</td>\n",
       "      <td>good.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23147</th>\n",
       "      <td>09b5bef434</td>\n",
       "      <td>hey, I can`t make it to Makers tonight</td>\n",
       "      <td>hey, I can`t make it to Makers tonight</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21547</th>\n",
       "      <td>83cdebaa92</td>\n",
       "      <td>Whats with you though, you sound a bit down y...</td>\n",
       "      <td>you sound a bit down yourself.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>914da6164e</td>\n",
       "      <td>No B2G1 for me.  Trying to save cash for next ...</td>\n",
       "      <td>No B2G1 for me.  Trying to save cash for next ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>d7709f9f53</td>\n",
       "      <td>hahahaha omg you win the internetz today!  'W...</td>\n",
       "      <td>a omg you win</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "19413  ba7bbe76fe                   : saw it yesterday. Pretty good.   \n",
       "23147  09b5bef434             hey, I can`t make it to Makers tonight   \n",
       "21547  83cdebaa92   Whats with you though, you sound a bit down y...   \n",
       "14162  914da6164e  No B2G1 for me.  Trying to save cash for next ...   \n",
       "6474   d7709f9f53   hahahaha omg you win the internetz today!  'W...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "19413                                              good.  positive  \n",
       "23147             hey, I can`t make it to Makers tonight   neutral  \n",
       "21547                     you sound a bit down yourself.  negative  \n",
       "14162  No B2G1 for me.  Trying to save cash for next ...   neutral  \n",
       "6474                                       a omg you win  positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = os.path.join(\"data\")\n",
    "df = pd.read_csv(os.path.join(base_dir, \"Tweets.csv\"))\n",
    "df = df[pd.notnull(df[\"text\"])] # GPT generated command to clean :)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=5496*2, train_size=16448, random_state=42)\n",
    "val_df_SAE, val_df_holdout = train_test_split(val_df, test_size=5496, train_size=5496, random_state=42)\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5a7c5",
   "metadata": {},
   "source": [
    "## 1. Feature Generation\n",
    "First, we will compute the embeddings of the `text` column for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d04300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model nomic-ai/modernbert-embed-base to cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e1b9d027a5495b8b06aa47b530b176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4280c36112fe4dd3bbb73361bc1e08d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunk 0:   0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 27440 embeddings to /home/phoenixw/HypotheSAEs/emb_cache/twitter_quickstart_local_nomic-ai/modernbert-embed-base/chunk_000.npy\n"
     ]
    }
   ],
   "source": [
    "texts = train_df[\"text\"].tolist()\n",
    "sentiments = train_df[\"sentiment\"].tolist()\n",
    "val_texts = val_df[\"text\"].tolist()\n",
    "\n",
    "EMBEDDER = \"nomic-ai/modernbert-embed-base\"\n",
    "CACHE_NAME = f\"twitter_quickstart_local_{EMBEDDER}\"\n",
    "\n",
    "text2embedding = get_local_embeddings(texts + val_texts, model=EMBEDDER, batch_size=128, cache_name=CACHE_NAME)\n",
    "train_embeddings = np.stack([text2embedding[text] for text in texts])\n",
    "val_embeddings = np.stack([text2embedding[text] for text in val_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c19e9f",
   "metadata": {},
   "source": [
    "Now that we have the embeddings, we will use a SAE wiil sparsify these representations. Since the size of the dataset used here and the dataset used in `quickstart_local.ipynb` are relatively similar, and after consulting the `README`, I decided to train a Matryoshka SAE with the same parameters $M=256$, $k=8$, and $\\text{prefix\\_lengths} = [32, 256]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af5b6dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d62884ea8de4213b526656f9dbc9ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 94 epochs\n",
      "Saved model to data/checkpoints/twitter_quickstart_local_nomic-ai/modernbert-embed-base/SAE_matryoshka_M=256_K=8_prefixes=32-256.pt\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = os.path.join(base_dir, \"checkpoints\", CACHE_NAME)\n",
    "sae = train_sae(embeddings=train_embeddings, M=256, K=8, matryoshka_prefix_lengths=[32, 256], checkpoint_dir=checkpoint_dir, val_embeddings=val_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8719a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HSAEs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
